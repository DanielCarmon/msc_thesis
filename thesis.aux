\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@input{msc_titles.aux}
\@input{acknowledgments.aux}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{4}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Introduction}{{1}{4}{Introduction}{chapter.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces  Weights learned by a fitting a logistic regression model on the MNIST dataset. Red represents negative weights, while blue represents positive weights. The Logistic Regression model learns correlation between individual features and labels.}}{5}{figure.1.1}}
\newlabel{fig:softmax-weights}{{1.1}{5}{Weights learned by a fitting a logistic regression model on the MNIST dataset. Red represents negative weights, while blue represents positive weights. The Logistic Regression model learns correlation between individual features and labels}{figure.1.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces  Test accuracy for some common models using na\IeC {\"\i }ve features}}{5}{table.1.1}}
\newlabel{tab:naive_features}{{1.1}{5}{Test accuracy for some common models using na√Øve features}{table.1.1}{}}
\citation{greenwade93}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}End-To-End Representation Learning}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{e2e_rep_learn}{{2}{7}{End-To-End Representation Learning}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Domain Adaptation and Zero-Shot Learning}{7}{section.2.1}}
\citation{mcdonald_non-projective_2005}
\citation{zhang_dependency_2016}
\citation{gupta_efficient_2007}
\citation{tarlow_fast_2012}
\citation{chang_learning_2008}
\citation{chang_guiding_2007}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Related Work}{9}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Related_Work}{{3}{9}{Related Work}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Structured Prediction with Constraints}{9}{section.3.1}}
\newlabel{struct_pred_constraint}{{3.1}{9}{Structured Prediction with Constraints}{section.3.1}{}}
\citation{ganchev_posterior_2010}
\citation{li_high_2014}
\citation{ren_structured_nodate}
\citation{mcclosky_effective_2006}
\citation{mcclosky_reranking_2006}
\citation{yu_domain_2015}
\citation{yu_exploring_2015}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Semi-Supervised Methods for Parsing}{10}{section.3.2}}
\citation{blum_combining_1998}
\citation{sogaard_semi-supervised_2010}
\citation{koo_simple_2008}
\citation{kiperwasser_semi-supervised_2015}
\citation{suzuki_empirical_2009}
\citation{chen_semi-supervised_2013}
\citation{li_active_2016}
\citation{gomez-rodriguez_transition-based_2010}
\citation{gomez-rodriguez_parsing_2009}
\citation{havelka_beyond_2007}
\citation{havelka_projectivity_2007}
\citation{kuhlmann_dependency_2010}
\citation{nivre_efficient_2003}
\citation{covington_fundamental_2001}
\citation{zhang_dependency_2016}
\citation{kiperwasser_simple_2016}
\citation{nivre_non-projective_2009}
\citation{mcdonald_non-projective_2005}
\citation{nivre_pseudo-projective_2005}
\citation{nivre_constraints_2006}
\citation{gomez-rodriguez_transition-based_2010}
\citation{gomez-rodriguez_parsing_2009}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Structural Properties of Dependency Structures}{12}{section.3.3}}
\newlabel{sec:structural_props_parse}{{3.3}{12}{Structural Properties of Dependency Structures}{section.3.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Deep K-Means++ Learning}{13}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Our Algorithm}{13}{section.4.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Deep K-Means++ Learning}}{14}{algorithm.1}}
\@writefile{toc}{\contentsline {subsubsection}{Sub-Problem Gradients}{15}{section*.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Differentiable K-Means Clustering}{16}{section.4.2}}
\newlabel{diff_clust}{{4.2}{16}{Differentiable K-Means Clustering}{section.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}The K-Means Objective}{16}{subsection.4.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Differentiable K-Means Iterations}{17}{subsection.4.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Block diagram for clustering module.}}{18}{figure.4.1}}
\newlabel{fig:frog}{{4.1}{18}{Block diagram for clustering module}{figure.4.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Deep K-Means++}}{19}{algorithm.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Get Distance Matrix}}{19}{algorithm.3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Infer-Beliefs}}{19}{algorithm.4}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces Infer-Centroids}}{19}{algorithm.5}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Differentiable Centroid Sampling}{20}{section.4.3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces Deep K-Means++ Init}}{20}{algorithm.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Gumbel-Softmax Sampling}{21}{subsection.4.3.1}}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {thm}{\numberline {4.3.1}Theorem}{21}{thm.4.3.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7}{\ignorespaces Gumbel-Softmax Sampling}}{22}{algorithm.7}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Experiments}{23}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{experiments}{{5}{23}{Experiments}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Experiments with synthetic data}{23}{section.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Learning a linear projection}{23}{subsection.5.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces  Example of a successful K-means clustering via Gradient Descent over the logits of cluster membership probabilities.}}{24}{figure.5.1}}
\newlabel{fig:gd_clust_good}{{5.1}{24}{Example of a successful K-means clustering via Gradient Descent over the logits of cluster membership probabilities}{figure.5.1}{}}
\citation{WahCUB_200_2011}
\citation{greenwade93}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Experiments With Real-World Data}{25}{section.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Datasets}{25}{subsection.5.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Experimental Protocol}{25}{subsection.5.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Implementation Details}{25}{subsection.5.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Results}{25}{subsection.5.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.5}General Details}{25}{subsection.5.2.5}}
\citation{greenwade93}
\citation{greenwade93}
\citation{greenwade93}
\citation{greenwade93}
\@writefile{toc}{\contentsline {subsubsection}{Depth of K-Means unrolling}{26}{section*.5}}
\@writefile{toc}{\contentsline {subsubsection}{Embedding Function}{26}{section*.6}}
\@writefile{toc}{\contentsline {subsubsection}{Training Details}{26}{section*.7}}
\citation{greenwade93}
\citation{greenwade93}
\@writefile{toc}{\contentsline {subsubsection}{Testing Details}{27}{section*.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.6}CUB Dataset}{28}{subsection.5.2.6}}
\@writefile{toc}{\contentsline {subsubsection}{Training Details}{28}{section*.9}}
\@writefile{toc}{\contentsline {subsubsection}{Results}{28}{section*.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces placeholder for image.}}{28}{figure.5.2}}
\newlabel{fig:frog}{{5.2}{28}{placeholder for image}{figure.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces  NMI evaluation on the Birds (CUB-200- 2011) dataset.}}{29}{table.5.1}}
\newlabel{tab:score compare}{{5.1}{29}{NMI evaluation on the Birds (CUB-200- 2011) dataset}{table.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.7}Stanford Cars Dataset}{29}{subsection.5.2.7}}
\@writefile{toc}{\contentsline {subsubsection}{Training Details}{29}{section*.11}}
\@writefile{toc}{\contentsline {subsubsection}{Results}{29}{section*.12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.8}Ablation Studies}{29}{subsection.5.2.8}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Discussion}{31}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:discussion}{{6}{31}{Discussion}{chapter.6}{}}
\bibstyle{alpha}
\bibdata{Zotero}
\bibcite{blum_combining_1998}{BM98}
\bibcite{covington_fundamental_2001}{Cov01}
\bibcite{chang_guiding_2007}{CRR07}
\bibcite{chang_learning_2008}{CRRR08}
\bibcite{chen_semi-supervised_2013}{CZZ13}
\bibcite{gupta_efficient_2007}{GDS07}
\bibcite{ganchev_posterior_2010}{GGT10}
\bibcite{gomez-rodriguez_transition-based_2010}{GRN10}
\bibcite{gomez-rodriguez_parsing_2009}{GRWC09}
\bibcite{havelka_beyond_2007}{Hav07a}
\bibcite{havelka_projectivity_2007}{Hav07b}
\bibcite{koo_simple_2008}{KCC08}
\bibcite{kiperwasser_semi-supervised_2015}{KG15}
\bibcite{kiperwasser_simple_2016}{KG16}
\bibcite{kuhlmann_dependency_2010}{Kuh10}
\bibcite{li_high_2014}{LZ14}
\bibcite{li_active_2016}{LZZ{$^{+}$}16}
\bibcite{mcclosky_effective_2006}{MCJ06a}
\bibcite{mcclosky_reranking_2006}{MCJ06b}
\bibcite{mcdonald_non-projective_2005}{MPRH05}
\bibcite{nivre_efficient_2003}{Niv03}
\bibcite{nivre_constraints_2006}{Niv06}
\bibcite{nivre_non-projective_2009}{Niv09}
\bibcite{nivre_pseudo-projective_2005}{NN05}
\bibcite{ren_structured_nodate}{RSS{$^{+}$}}
\bibcite{suzuki_empirical_2009}{SICC09}
\bibcite{sogaard_semi-supervised_2010}{SR10}
\bibcite{tarlow_fast_2012}{TSZ{$^{+}$}12}
\bibcite{yu_exploring_2015}{YB15}
\bibcite{yu_domain_2015}{YEB15}
\bibcite{zhang_dependency_2016}{ZCL16}
